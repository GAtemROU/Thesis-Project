\chapter{Conclusion and General Discussion}
\label{chap:conclusion}

\section{Conclusion}
\label{sec:conclusion}

In this thesis, we approached the research question from multiple analytical angles to better understand how visual attention relates to reasoning in reference games. First, we conducted a pairwise correlation analysis between eye-tracking features and two key trial-level outcomes: accuracy and response time. Next, we built a logistic regression model to predict whether a given trial would be solved correctly, based on the participant's gaze behavior. To further investigate the role of attention, we implemented two additional logistic regression models that focused on specific fixation patterns: one predicted whether a gaze point would land on the Distractor, and the other did the same for the bank of available messages. Finally, we analyzed participants' self-reported strategies and labeled them according to the Rational Speech Act (RSA) framework ($L_0$, $L_1$, $L_2$). This allowed us to compare how different reasoning strategies manifest in distinct attentional profiles.

Although participants seem to grasp the problem in a similar way, their answers still differ quite a lot. We saw this from the fact that the Distractor did not turn out to be associated with accuracy, even though it is a very important piece of information for the Complex trials. Thus, participants fail the trials not because they miss an important piece of information as we hypothesized in \autoref{sec:rsa}, where we showed that not looking at the Distractor would make the Complex condition unsolvable. The problem appears to lie in how participants interpret or apply the information they attend to, rather than in what information they access.

The consistent association between accuracy and proportional time spent on the bank of available messages suggests that this behavior may reflect more than simple visual scanning. It is plausible that participants engage in matching messages to objects, or in other forms of referential reasoning. In the context of reference games, such (possibly recursive) reasoning processes are essential. Thus, increased attention to the available messages may serve as an indicator of deeper or more robust reasoning, ultimately leading to higher accuracy.

While we could not directly infer participants' reasoning strategies, we were able to identify eye-tracking features associated with trial accuracy. Further research might include more sophisticated analysis to identify the actual strategies of the participants. The main finding suggests that the bank of available messages is an important area of interest when predicting whether a person is going to solve the trial correctly. A possible future work might include detecting which messages the participants are looking at and how they are using them. This reflects a design limitation: anticipating potential quality issues with WebGazer, we placed the available messages close together -- thus sacrificing the ability to detect which message the participants are looking at. However, this is a very interesting question and could be a good future work.

Ongoing research on modeling participant behavior in reference games using ACT-R \citep{Duff_2025} may provide deeper insights into the cognitive strategies underlying their responses.

This thesis contributes to a wider ongoing research on reference games. Overall, this work demonstrates that even with limited-resolution eye-tracking data, meaningful patterns can be extracted that shed light on participants' reasoning processes in reference games. This thesis provides a strong foundation for future work that would include eye-tracking data in reference games or another type of experiment with a similar setup. 


\section{General Discussion}
\label{sec:general-discussion}

\subsection{Scanpaths}
\label{sec:general-discussion:scanpaths}
In this study, did not account for  the order of the gaze points. However, the scanpath by itself includes this information. We were unable to come up with a good strategy how one could encode the scanpath in a way that would be useful and feasible for the analysis. The scanpaths are not fixed length, posing a problem that every entry would be of a different length which would make it impossible to use them in a model. One idea could be to use RNNs to analyze the scanpaths, however, this would require a lot of data and a lot of tuning. We did a few attempts in training CNNs on the generated plots of the scanpaths, however, the results were not promising and due to low interpretability of the model and time constraints we decided to focus on the more traditional features.

\subsection{Peripheral Vision}
\label{sec:general-discussion:attention-and-eye-tracking}
It is possible that the participants used their peripheral vision to look at the objects. If one specifically tries to solve the trial without moving the eyes, one could still do it. This definitely poses a problem for the eye-tracking data, as it would be impossible to detect this kind of behavior. We do not have any evidence that this is the case, but it is a possibility. People would not specifically try to solve the trials without the eye movements, however, it is quite probable that they capture some features such as color of the Distractor in case that the sent message is a shape during the trial. This is somewhat supported by the likelihood model predicting whether a gaze point would end up on the Distractor or not \autoref{sec:distractor_model}. \texttt{MsgType} had a very low but significant coefficient indicating exactly this behavior. Although this is not a strong evidence for the peripheral vision, the potential problem should be taken into account.


\subsection{Toggling}
\label{sec:general-discussion:toggling}
We only implemented features that describe proportional time spent on the area of interest. However, as we described in the \autoref{sec:conclusion}, an increase in proportional time on available messages might indicate a deeper reasoning process. One could also think about defining a feature to describe the toggling between the available messages and other areas of interest. Similarly to how it was done in \cite{Vigneau_2006}. The toggling might be an important predictor for accuracy if one makes repeated matches of the messages and the objects. 

\subsection{Proportional Eye Tracking Features}
\label{sec:general-discussion:proportional-eye-tracking-features}
We suspect that the proportional eye-tracking features might be influenced by the very last look at one of the objects. Therefore, making them good predictors of accuracy, as we saw in \autoref{sec:accuracy_model} or \autoref{sec:pairwise_corr}. The Competitor and Distractor turned out to be decisive for the accuracy of the predictions. This indicates that people look more at the object they would choose. As for the future work, one should consider trimming the last saccade before the decision, this should make the proportional features more reliable. On the other hand, if this does not solve the issue, this would indicate that people tend to make a decision not in the end of the trial. This would also be an interesting finding.

The way we assigned the fixations to the stimuli is not optimal as we clearly disregarded the timings of the gaze predictions as well as added some of the gaze points that are from saccades rather than from fixations. Both of the problems could have been solved with a fixation detection algorithm. A more advanced fixation detection algorithm could be implemented in the future to improve the preprocessing part of the data analysis. Currently as was discussed in \autoref{sec:analysis:eyetr} the fixation detection algorithm falls short in the case of low sampling rates that WebGazer demonstrates. The algorithm is unable to detect some fixations in the data, which can lead to a loss of information.

\subsection{Eye Tracking}
\label{sec:general-discussion:eye-tracking}
The eye-tracking data collected by WebGazer was definitely worse than one could collect in the lab. However, clearly this thesis is an example that it is possible to conduct an eye-tracking experiment with WebGazer. The data is not perfect, but it is good enough to be able to draw some conclusions from it. However, the library is far from perfect and definitely needs a lot of adjustments to the specific setups one could be interested in. Designing the experiment took far more time than the actual analysis of the data. Each participant has a different setup. And, although, the calibration of the eye tracker must be conducted quite strictly, it is also important to make sure that the calibration is doable for the participants. We have achieved some balance between the two, but there is still a lot of room for improvement.

On the other hand, WebGazer has a few clear advantages. First of all, the fact that it is possible to collect data from a large number of participants. This is something that is not possible in the lab, especially for an eye-tracking study as it would require individual treatment of each participant, as oppose to each participant working in parallel in the online experiment. Secondly, WebGazer is free and open source, which makes it available for everyone. This is a clear advantage over the lab eye trackers that are expensive and not available for everyone. 